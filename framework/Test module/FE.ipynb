{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module contains functionality for FE simulations and preprocessing of the data for Machine Learnig.\n",
    "\n",
    "The module currently contains the following class:\n",
    "\n",
    "\n",
    "\n",
    "- Pre_process     :    This class pre-process the data for Finite element simulations based on user \n",
    "                       input in config.yaml files and generate new .key files in a new folder for \n",
    "                       simulation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy.stats import uniform\n",
    "import yaml\n",
    "from qd.cae.dyna import KeyFile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import subprocess \n",
    "import shlex\n",
    "from diversipy.hycusampling import maximin_reconstruction as maxmin\n",
    "import csv\n",
    "\n",
    "class FE():\n",
    "    \"\"\"\n",
    "    This Class contains set of methods which performs reading of the .yaml file and replaces values of the input parameters \n",
    "    with newly generated sample data sets. And then, new key files are generated for simulation. \n",
    "    \n",
    "    -----------\n",
    "       INPUTS  \n",
    "    -----------\n",
    "            settigs : Input file for FE simulations to get the user input                \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, settings):\n",
    " \n",
    "        self.settings = settings\n",
    "        self.folders_count=0\n",
    "        self._get_user_input()\n",
    "     \n",
    "    def _get_user_input(self):\n",
    "        \n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "#         global fin_dir\n",
    "#         global dir_main\n",
    "        with open(self.settings,'r') as file:\n",
    "            inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        inp_vals=[*inp.values()]\n",
    "        inp_keys=[*inp.keys()]\n",
    "        \n",
    "        req=['Newfolder_name','Runs','key','config','LS_Run_path','NCPU','type','meta_exec','ses_path','ses_file'] \n",
    "        \n",
    "        for names in req:\n",
    "            if names not in inp_keys:\n",
    "                raise Exception(names +\" not in settings.yaml file\")\n",
    "            if inp[names] == None:\n",
    "                raise Exception(names +\" value not in settings.yaml file\")\n",
    "                \n",
    "        if isinstance(inp['Runs'], int) == True:\n",
    "            self.Run=inp['Runs']\n",
    "            self.int='yes'\n",
    "            self.Flag=1\n",
    "        elif isinstance(inp['Runs'], str) == True:\n",
    "            self.DOE=pd.read_csv(inp['Runs'])\n",
    "            self.int='no'\n",
    "            self.Run=len(self.DOE)\n",
    "            self.Flag=1\n",
    "        else:\n",
    "            print('Enter either a Integer or a .csv Input')\n",
    "        \n",
    "        dir_main=None   \n",
    "        for i in range(0,len(inp_keys)):\n",
    "            if inp_keys[i] =='Directory':\n",
    "                dir_main=inp_vals[i]\n",
    "            if inp_keys[i] =='Newfolder_name':\n",
    "                file_name=inp_vals[i]\n",
    "#             elif inp_keys[i] =='Runs':\n",
    "#                 self.Run=inp_vals[i]\n",
    "            elif inp_keys[i] =='key':\n",
    "                self.key=inp_vals[i]\n",
    "            elif inp_keys[i] =='config':\n",
    "                self.para_list=inp_vals[i]\n",
    "            elif inp_keys[i] =='LS_Run_path':\n",
    "                self.ls_run_exe = inp_vals[i]\n",
    "            elif inp_keys[i] =='NCPU':\n",
    "                self.ncpu=inp_vals[i]\n",
    "            elif inp_keys[i] =='meta_exec':\n",
    "                self.meta_exe=inp_vals[i]\n",
    "            elif inp_keys[i] =='ses_path':\n",
    "                self.ses_path=inp_vals[i]\n",
    "            elif inp_keys[i] =='ses_file':\n",
    "                self.ses=inp_vals[i]\n",
    "                \n",
    "        if dir_main == None:\n",
    "            current_directory = os.getcwd()\n",
    "            self.fin_dir = os.path.join(current_directory,file_name)\n",
    "        else:      \n",
    "            self.fin_dir = os.path.join(dir_main,file_name)      \n",
    "        try:\n",
    "            os.mkdir(self.fin_dir)\n",
    "        except OSError as err:\n",
    "#             print(err)\n",
    "            print('Adding new samples to the existing directory')\n",
    "            self.Flag=0\n",
    "        self._set_keypath()\n",
    "                \n",
    "        return self.fin_dir , self.Run , self.key , self.para_list\n",
    "                      \n",
    "    def _set_keypath(self):\n",
    "        \n",
    "        \"\"\" changes the *INCLUDE PATH card in the key file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dir_main : path of the directory the other .k files are present\n",
    "        file_name: Name of the newly created file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.newkey : a new key file with an updated file path.\n",
    "        \n",
    "        \"\"\"\n",
    "        k = KeyFile(self.key)\n",
    "        include_path = k[\"*INCLUDE_PATH\"][0]\n",
    "        include_path[0] = self.fin_dir.replace('\\\\','/')\n",
    "        curr_path=os.getcwd()\n",
    "        os.chdir(self.fin_dir)\n",
    "        k.save(\"upd_key.key\")\n",
    "        os.chdir(curr_path)\n",
    "        self.newkey ='upd_key.key'\n",
    "        \n",
    "        return self.newkey\n",
    "    \n",
    "    def Read_config(self):\n",
    "        \"\"\" converts the .yaml file to a dictionary\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.para_list : the config.yaml file  with the user inputs\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        z : the .yaml file in dictionary format\n",
    "        \n",
    "        \"\"\"  \n",
    "        with open(self.para_list,'r') as file:\n",
    "            parameter_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        dynParams = {k: v for k, v in parameter_list['parameters'].items() if parameter_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "        self.dynaParameters = pd.DataFrame.from_dict(dynParams)\n",
    "        \n",
    "        return self.dynaParameters\n",
    "    \n",
    "\n",
    "    def get_samples(self): \n",
    "        \n",
    "        \"\"\" samples the data based on the .yaml file using normal distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "#         global Data\n",
    "#         Data=[]\n",
    "#         Data = lhs(self.para_num, samples=self.Run)\n",
    "#         means = var[0]\n",
    "#         stdvs = var[1]\n",
    "#         for i in range(0,self.para_num,1):\n",
    "#             Data[:, i] = norm(loc=means[i], scale=stdvs[i]).ppf(Data[:, i])\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "\n",
    "        if self.int =='yes':\n",
    "            self.DOE = lhs(len(self.dynaParameters.loc['parameter']),samples = self.Run)\n",
    "            save_file=pd.DataFrame(self.DOE)\n",
    "            os.chdir(self.fin_dir)\n",
    "            save_file.to_csv('DOE.csv', index=False)\n",
    "            minimum_val = self.dynaParameters.loc['min']\n",
    "            maximum_val = self.dynaParameters.loc['max']\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                self.DOE[:,i]=uniform(minimum_val[i], maximum_val[i]-minimum_val[i]).ppf(self.DOE[:, i])\n",
    "                \n",
    "        elif self.int=='no':\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', index=False)\n",
    "#             df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "            \n",
    "        return self.DOE\n",
    "    \n",
    "    def add_samples(self):\n",
    "        os.chdir(self.fin_dir)\n",
    "        if os.path.isfile('DOE.csv'):\n",
    "            old_DOE=pd.read_csv('DOE.csv')\n",
    "        else:\n",
    "            print('No preexisting DOE found!')\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "        if self.int=='yes':\n",
    "            data_add = lhs(len(self.dynaParameters.loc['parameter']), samples=self.Run)\n",
    "            self.DOE = maxmin(self.Run,len(self.dynaParameters.loc['parameter']), num_steps=None, initial_points=data_add, existing_points=old_DOE, use_reflection_edge_correction=None, dist_matrix_function=None, callback=None)\n",
    "#             save_DOE=old_DOE.append(pd.DataFrame(self.DOE), ignore_index=True)\n",
    "            df=pd.DataFrame(self.DOE)\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            min_newsample_val = self.dynaParameters.loc['min']\n",
    "            max_newsample_val = self.dynaParameters.loc['max']\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                self.DOE[:,i]=uniform(min_newsample_val[i], max_newsample_val[i]-min_newsample_val[i]).ppf(self.DOE[:, i])\n",
    "        elif self.int=='no':\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "\n",
    "        return self.DOE\n",
    "                       \n",
    "    def generate_key_file(self):\n",
    "        \n",
    "        \"\"\" Generate the new updated .key file and a FE_Parameters.yaml file containing respective sampled values \n",
    "        for each parameters in new folders.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.newkey      : a new key file with an updated file path.\n",
    "        fin_dir          : final path of the created directory\n",
    "        self.Run         : Number of samples required \n",
    "        self.para_num    : number of parameters/variables/features\n",
    "        self.para_names  : Names of parameters/variables/features\n",
    "        Data             : samples matrix in a list\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\"\n",
    "        os.chdir(self.fin_dir)\n",
    "        kf=KeyFile(self.newkey)  \n",
    "        key_parameters=kf[\"*PARAMETER\"][0]\n",
    "        key_parameters_array=np.array(kf[\"*PARAMETER\"][0])\n",
    "        \n",
    "        # Creating a dictionary with key and it's values:\n",
    "        key_dict={}\n",
    "        R_index=[]\n",
    "        for i in range(0,len(key_parameters_array)):\n",
    "            if key_parameters_array[i].startswith('R'):\n",
    "                R_index.append(i)\n",
    "                f=key_parameters_array[i].split(' ')\n",
    "                key_dict[f[1]]=f[-1]\n",
    "        par_lis=[*key_dict.keys()]\n",
    "        os.chdir(self.fin_dir)\n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith('Run')])\n",
    "\n",
    "        \n",
    "        for run in range(0,self.Run):\n",
    "            \n",
    "            os.mkdir('Run_'+str(run+self.folders_count+1))\n",
    "            os.chdir('Run_'+str(run+self.folders_count+1))\n",
    "            FE_Parameters = {}\n",
    "            \n",
    "            for para in range(0,len(self.col_names)):\n",
    "                \n",
    "                for i in range(0,len(R_index)):\n",
    "                    \n",
    "                    if par_lis[i] == self.col_names[para]:\n",
    "                        \n",
    "                        key_parameters[i+1,1] = self.DOE[run,para]                 \n",
    "                        kf.save(\"run_main_{}.key\".format(str(run+self.folders_count+1)))\n",
    "                        FE_Parameters[par_lis[i]] =  key_parameters[i+1,1]\n",
    "                    with open('FE_Parameters.yaml','w') as FE_file:\n",
    "                        yaml.dump(FE_Parameters,FE_file,default_flow_style = False)\n",
    "            os.chdir(self.fin_dir)    \n",
    "#         self.change_directory(main_path)                \n",
    "        \n",
    "    def get_simulation_files(self):\n",
    "        \"\"\" \n",
    "        Runs all the methods of pre-process class\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Read_config()\n",
    "        if self.Flag==1:\n",
    "            self.get_samples()\n",
    "        elif self.Flag==0:\n",
    "            self.add_samples()\n",
    "        self.generate_key_file()\n",
    "         \n",
    "        \n",
    "    def Run_LS(self):\n",
    "        os.chdir(self.fin_dir)\n",
    "        for i in range(0,self.Run):\n",
    "            path = 'Run_'+str(self.folders_count+i+1)\n",
    "            ar=os.path.join(self.fin_dir,path)\n",
    "            os.chdir(ar)\n",
    "            subprocess.call(r'{} i=run_main_{}.key NCPU={}'.format(self.ls_run_exe,(self.folders_count+i+1),self.ncpu))  \n",
    "#             os.chdir(self.fin_dir)\n",
    "\n",
    "    def read_meta(self):\n",
    "        meta_exec = self.meta_exe\n",
    "        meta_session_file_path = self.ses_path\n",
    "        meta_session_file_name = self.ses\n",
    "        session = meta_session_file_path + meta_session_file_name\n",
    "        meta_options = \" -b -noses -fastses -s \"\n",
    "        metapost_command = meta_exec + meta_options + session\n",
    "        simulation_path = self.sim_path\n",
    "#         orig_dir=os.getcwd()\n",
    "        os.chdir(simulation_path)\n",
    "        process_command=shlex.split(metapost_command)\n",
    "        command_process=subprocess.Popen(process_command, stdout=subprocess.PIPE)\n",
    "        output, err = command_process.communicate() \n",
    "#         os.chdir(orig_dir)\n",
    "\n",
    "    def get_results(self):\n",
    "        result={}          \n",
    "        for runs in range(0,self.Run):\n",
    "            os.chdir(self.fin_dir)\n",
    "            self.sim_path = 'Run_'+str(self.folders_count+runs+1)\n",
    "            self.read_meta()\n",
    "            \n",
    "            hic=pd.read_csv(\"HIC15.csv\")\n",
    "            chest=pd.read_csv(\"chest_def.csv\")\n",
    "            neck=pd.read_csv(\"Neck_Fz.csv\")\n",
    "            result['HIC 15']=max(hic[hic.columns[1]])\n",
    "            result['Chest Deflection [mm]']=min(chest[chest.columns[1]])\n",
    "            result['Neck Force_z [kN]']=max(neck[neck.columns[1]])\n",
    "#             df = pd.read_csv(\"{}/{}/HIC15.csv\".format(self.fin_dir.replace('\\\\','/'),self.sim_path),skiprows = 5,nrows=1)\n",
    "#             HIC['HIC_15'] = result[0][1] \n",
    "            with open('result.yaml','w') as result_file:\n",
    "                yaml.dump(result,result_file,default_flow_style = False)\n",
    "                \n",
    "    def get_dataset(self):\n",
    "        os.chdir(self.fin_dir)\n",
    "        indx=len([name for name in os.listdir(os.getcwd()) if name.startswith('Run')])\n",
    "        Result_set = pd.DataFrame(data=None,columns=None,dtype=None,copy=False)\n",
    "        for j in range(0,indx):\n",
    "            os.chdir('Run_{}'.format(self.folders_count+j+1))\n",
    "            with open('FE_Parameters.yaml','r') as file:\n",
    "                inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "            with open('result.yaml','r') as file:\n",
    "                out = yaml.load(file, Loader=yaml.FullLoader) \n",
    "            df_input_set = pd.DataFrame.from_dict(inp, orient='index').T\n",
    "            df_output_set = pd.DataFrame.from_dict(out, orient='index').T\n",
    "            df_input_set[df_output_set.columns]=df_output_set.values\n",
    "            Result_set=Result_set.append(df_input_set,ignore_index=True)\n",
    "            os.chdir(self.fin_dir)\n",
    "        Result_set.to_csv(\"Inputs_outputs_dataset.csv\", index=False)\n",
    "                 \n",
    "    def Run_all(self):\n",
    "        self.get_simulation_files()\n",
    "        self.Run_LS()\n",
    "        self.get_results()\n",
    "        self.get_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
