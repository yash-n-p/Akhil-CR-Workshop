{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE\n",
    "\n",
    "> This module contains functionality for FE simulations and generating dataset for Machine Learnig.This module    hosts all the functions dealing with FE simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy.stats import uniform\n",
    "import yaml\n",
    "from qd.cae.dyna import KeyFile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import subprocess \n",
    "import shlex\n",
    "\n",
    "class FE():\n",
    "    \"\"\"\n",
    "    This Class contains set of methods which performs reading of the .yaml file and replaces values of the input parameters \n",
    "    with newly generated sample data sets. And then, new key files are generated for simulation. and also inclues runnings the simulations in LsDyna\n",
    "    using the generated key files and postprocessing the results using Metapost.\n",
    "    \n",
    "    -----------\n",
    "       INPUTS  \n",
    "    -----------\n",
    "            settigs : Input file for FE simulations to get the user input                \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, settings):\n",
    " \n",
    "        self.settings = settings\n",
    "        self._get_user_input()\n",
    "     \n",
    "    def _get_user_input(self):  \n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        self.ls_run_exe :   exectuable file for Ls run\n",
    "        self.ncpu       :   Numebr of memory to run LsDyna \n",
    "        self.meta_exe   :   Metapost batch command (depends on your installation of Metapost)\n",
    "        self.ses_path   :   Meta session file path\n",
    "        self.ses        :   Meta session file\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.settings,'r') as file:\n",
    "            inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        inp_vals=[*inp.values()]\n",
    "        inp_keys=[*inp.keys()]\n",
    "        \n",
    "        req=['Newfolder_name','Runs','key','config','LS_Run_path','NCPU','type','meta_exec','ses_path','ses_file'] \n",
    "        \n",
    "        for name in req:\n",
    "            if name not in inp_keys:\n",
    "                raise Exception(name +\" not in settings.yaml file\")\n",
    "                \n",
    "            if inp[name] == None:\n",
    "                raise Exception(name +\" value not in settings.yaml file\")\n",
    "                \n",
    "        if isinstance(inp['Runs'], int) == False:\n",
    "            raise Exception(\"Enter a integer value for Run in settings.yaml\")\n",
    "        \n",
    "        for i in range(0,len(inp_keys)):\n",
    "            if inp_keys[i] =='Newfolder_name':\n",
    "                file_name=inp_vals[i]\n",
    "            elif inp_keys[i] =='Runs':\n",
    "                self.Run=inp_vals[i]\n",
    "            elif inp_keys[i] =='key':\n",
    "                self.key=inp_vals[i]\n",
    "            elif inp_keys[i] =='config':\n",
    "                self.para_list=inp_vals[i]\n",
    "            elif inp_keys[i] =='LS_Run_path':\n",
    "                self.ls_run_exe = inp_vals[i]\n",
    "            elif inp_keys[i] =='NCPU':\n",
    "                self.ncpu=inp_vals[i]\n",
    "            elif inp_keys[i] =='meta_exec':\n",
    "                self.meta_exe=inp_vals[i]\n",
    "            elif inp_keys[i] =='ses_path':\n",
    "                self.ses_path=inp_vals[i]\n",
    "            elif inp_keys[i] =='ses_file':\n",
    "                self.ses=inp_vals[i]\n",
    "            \n",
    "        current_directory = os.getcwd()        \n",
    "        self.fin_dir = os.path.join(current_directory,file_name)      \n",
    "        try:\n",
    "            os.mkdir(self.fin_dir)\n",
    "        except OSError as err:\n",
    "            print(err)\n",
    "        \n",
    "        self._set_keypath()\n",
    "                \n",
    "        return self.fin_dir , self.Run , self.key , self.para_list\n",
    "                      \n",
    "    def _set_keypath(self): \n",
    "        \"\"\" changes the *INCLUDE PATH card in the key file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.fin_dir: Path of include dyna files \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.newkey : a new key file with an updated file path.\n",
    "        \n",
    "        \"\"\"\n",
    "        k = KeyFile(self.key)\n",
    "        include_path = k[\"*INCLUDE_PATH\"][0]\n",
    "        include_path[0] = self.fin_dir.replace('\\\\','/')\n",
    "        k.save(\"upd_key.key\")\n",
    "        self.newkey ='upd_key.key'\n",
    "        \n",
    "        return self.newkey\n",
    "    \n",
    "    def Read_config(self):\n",
    "        \"\"\" converts the .yaml file to a dataframe\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.para_list : the config.yaml file  with the user inputs\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.dynaParameters : Dataframe consisting yaml file data\n",
    "        \n",
    "        \"\"\"  \n",
    "        with open(self.para_list,'r') as file:\n",
    "            parameter_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        dynParams = {k: v for k, v in parameter_list['parameters'].items() if parameter_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "        self.dynaParameters = pd.DataFrame.from_dict(dynParams)\n",
    "        \n",
    "        return self.dynaParameters\n",
    "    \n",
    "\n",
    "    def get_samples(self):      \n",
    "        \"\"\" samples the data based on the .yaml file using lhs library and Uniform distribution\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.dynaParameters  : Dataframe consisting yaml file data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.DOE   : sampled Dataframe\n",
    "        \n",
    "        \"\"\" \n",
    "#         global Data\n",
    "#         Data=[]\n",
    "#         Data = lhs(self.para_num, samples=self.Run)\n",
    "#         means = var[0]\n",
    "#         stdvs = var[1]\n",
    "#         for i in range(0,self.para_num,1):\n",
    "#             Data[:, i] = norm(loc=means[i], scale=stdvs[i]).ppf(Data[:, i])\n",
    "            \n",
    "        self.DOE = lhs(len(self.dynaParameters.loc['parameter']),samples = self.Run)\n",
    "        minimum_val = self.dynaParameters.loc['min']\n",
    "        maximum_val = self.dynaParameters.loc['max']\n",
    "        for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "            self.DOE[:,i]=uniform(minimum_val[i], maximum_val[i]-minimum_val[i]).ppf(self.DOE[:, i])\n",
    "        return self.DOE\n",
    "    \n",
    "    def generate_key_file(self):   \n",
    "        \"\"\" Generate the new updated .key file and a FE_Parameters.yaml file containing respective sampled values \n",
    "        for each parameters in new folders.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.newkey          : a new key file with an updated file path.\n",
    "        self.fin_dir         : final path of the created directory\n",
    "        self.Run             : Number of samples required \n",
    "        self.dynaParameters  : Dataframe consisting yaml file data\n",
    "        self.DOE             : sampled Dataframe\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "         Generates new keyfile directories with FE_parameters.yaml for each sample set.\n",
    "        \n",
    "        \"\"\"\n",
    "        kf=KeyFile(self.newkey)  \n",
    "        key_parameters=kf[\"*PARAMETER\"][0]\n",
    "        key_parameters_array=np.array(kf[\"*PARAMETER\"][0])\n",
    "        \n",
    "        # Creating a dictionary with key and it's values:\n",
    "        key_dict={}\n",
    "        R_index=[]\n",
    "        for i in range(0,len(key_parameters_array)):\n",
    "            if key_parameters_array[i].startswith('R'):\n",
    "                R_index.append(i)\n",
    "                f=key_parameters_array[i].split(' ')\n",
    "                key_dict[f[1]]=f[-1]\n",
    "        par_lis=[*key_dict.keys()]\n",
    "        os.chdir(self.fin_dir)\n",
    "        \n",
    "        for run in range(0,self.Run):\n",
    "            \n",
    "            os.mkdir('Run_'+str(run+1))\n",
    "            os.chdir('Run_'+str(run+1))\n",
    "            FE_Parameters = {}\n",
    "            \n",
    "            for para in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                \n",
    "                for i in range(0,len(R_index),1):\n",
    "                    \n",
    "                    if par_lis[i] == self.dynaParameters.loc['parameter'][para]:\n",
    "                        \n",
    "                        key_parameters[i+1,1] = self.DOE[run,para]                 \n",
    "                        kf.save(\"run_main_{}.key\".format(str(run+1)))\n",
    "                    FE_Parameters[par_lis[i]] =  key_parameters[i+1,1]\n",
    "                    with open('FE_Parameters.yaml','w') as FE_file:\n",
    "                        yaml.dump(FE_Parameters,FE_file,default_flow_style = False)\n",
    "            os.chdir(self.fin_dir)                \n",
    "        \n",
    "    def get_simulation_files(self):\n",
    "        \"\"\" \n",
    "        Runs all the methods of pre-process class\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Read_config()\n",
    "        self.get_samples()\n",
    "        self.generate_key_file()\n",
    "         \n",
    "        \n",
    "    def Run_LS(self):\n",
    "        \"\"\" \n",
    "        Runs LsDyna\n",
    "        \n",
    "        \"\"\"\n",
    "        os.chdir(self.fin_dir)\n",
    "        for i in range(0,self.Run):\n",
    "            path = 'Run_'+str(i+1)\n",
    "            ar=os.path.join(self.fin_dir,path)\n",
    "            os.chdir(ar)\n",
    "            subprocess.call(r'{} i=run_main_{}.key NCPU={}'.format(self.ls_run_exe,(i+1),self.ncpu))  \n",
    "\n",
    "\n",
    "    def read_meta(self):\n",
    "        \"\"\" \n",
    "        Reads .ses for meta postprocessing\n",
    "        \n",
    "        \"\"\"\n",
    "        meta_exec = self.meta_exe\n",
    "        meta_session_file_path = self.ses_path\n",
    "        meta_session_file_name = self.ses\n",
    "        session = meta_session_file_path + meta_session_file_name\n",
    "        meta_options = \" -b -noses -fastses -s \"\n",
    "        metapost_command = meta_exec + meta_options + session\n",
    "        simulation_path = self.sim_path\n",
    "        os.chdir(simulation_path)\n",
    "        process_command=shlex.split(metapost_command)\n",
    "        command_process=subprocess.Popen(process_command, stdout=subprocess.PIPE)\n",
    "        output, err = command_process.communicate() \n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\" \n",
    "        Running Meta post to get results\n",
    "        \n",
    "         Returns\n",
    "        -------\n",
    "         returns .yaml file with specified injury results\n",
    "        \n",
    "        \"\"\"\n",
    "        result=[]\n",
    "        HIC = {}              \n",
    "        for runs in range(0,self.Run):\n",
    "            os.chdir(self.fin_dir)\n",
    "            self.sim_path = 'Run_'+str(runs+1)\n",
    "            self.read_meta()\n",
    "            df = pd.read_csv(\"{}/{}/HIC_15.csv\".format(self.fin_dir.replace('\\\\','/'),self.sim_path),skiprows = 5,nrows=1)\n",
    "            result = df.values.tolist()\n",
    "            HIC['HIC_15'] = result[0][1] \n",
    "            with open('HIC.yaml','w') as result_file:\n",
    "                yaml.dump(HIC,result_file,default_flow_style = False)\n",
    "                \n",
    "    def get_dataset(self):\n",
    "        \"\"\" read and joins the input and output yaml file from each simulation folder\n",
    "        and saves it in a Inputs_outputs_dataset.csv file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "         Inputs_outputs_dataset.csv\n",
    "        \n",
    "        \"\"\"\n",
    "        os.chdir(self.fin_dir)\n",
    "        Result_set = pd.DataFrame(data=None,columns=None,dtype=None,copy=False)\n",
    "        for j in range(0,self.Run):\n",
    "            os.chdir('Run_{}'.format(j+1))\n",
    "            with open('FE_Parameters.yaml','r') as file:\n",
    "                inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "            with open('HIC.yaml','r') as file:\n",
    "                out = yaml.load(file, Loader=yaml.FullLoader) \n",
    "            df_input_set = pd.DataFrame.from_dict(inp, orient='index').T\n",
    "            df_output_set = pd.DataFrame.from_dict(out, orient='index').T\n",
    "            df_input_set[df_output_set.columns]=df_output_set.values\n",
    "            Result_set=Result_set.append(df_input_set,ignore_index=True)\n",
    "            os.chdir(self.fin_dir)\n",
    "        Result_set.to_csv(\"Inputs_outputs_dataset.csv\", index=False)\n",
    "                 \n",
    "    def Run_all(self): \n",
    "        ''' Runs all the methods to get the final data set \n",
    "            which contains input and output data based on config.yaml file\n",
    "        '''  \n",
    "        self.get_simulation_files()\n",
    "        self.Run_LS()\n",
    "        self.get_results()\n",
    "        self.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
